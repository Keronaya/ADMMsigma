ADMMsigma
================

See [vignette](https://htmlpreview.github.io/?https://github.com/MGallow/ADMMsigma/blob/master/vignette/ADMMsigma.html) or [manual](https://github.com/MGallow/ADMMsigma/blob/master/ADMMsigma.pdf).

Overview
--------

<br>

<p align="center">
<img src="lik.gif">
</p>
<br>

`ADMMsigma` is an R package that estimates a penalized precision matrix via the alternating direction method of multipliers (ADMM) algorithm. A (possibly incomplete) list of functions contained in the package can be found below:

-   `ADMMsigma()` computes the estimated precision matrix (ridge, lasso, and elastic-net type regularization optional)

Installation
------------

``` r
# The easiest way to install is from the development version from GitHub:
# install.packages("devtools")
devtools::install_github("MGallow/ADMMsigma")
```

If there are any issues/bugs, please let me know: [github](https://github.com/MGallow/ADMMsigma/issues). You can also contact me via my [website](http://users.stat.umn.edu/~gall0441/). Pull requests are welcome!

Usage
-----

``` r
library(ADMMsigma)

# generate data from tri-diagonal (sparse) matrix for example
# first compute covariance matrix (can confirm inverse is tri-diagonal)
S = matrix(0, nrow = 10, ncol = 10)

for (i in 1:10){
  for (j in 1:10){
    S[i, j] = 0.7^(abs(i - j))
  }
}

# generate 100x10 matrix with rows drawn from iid N_p(0, S)
Z = matrix(rnorm(100*10), nrow = 100, ncol = 10)
out = eigen(S, symmetric = TRUE)
S.sqrt = out$vectors %*% diag(out$values^0.5) %*% t(out$vectors)
X = Z %*% S.sqrt


# ridge penalty (use CV for optimal lambda)
ADMMsigma(X, alpha = 0)
```

    ## 
    ## Iterations:
    ## [1] 32
    ## 
    ## Tuning parameters:
    ##        lam  alpha
    ## [1,]  -1.5      0
    ## 
    ## Omega:
    ##           [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]
    ##  [1,]  2.13203 -1.12034 -0.42846 -0.01131  0.26324 -0.09482 -0.23819
    ##  [2,] -1.12034  2.19577 -0.78877 -0.18507  0.22858  0.01596  0.09861
    ##  [3,] -0.42846 -0.78877  2.30765 -0.79144 -0.32394 -0.08071  0.16192
    ##  [4,] -0.01131 -0.18507 -0.79144  2.25701 -1.08300  0.01634 -0.16922
    ##  [5,]  0.26324  0.22858 -0.32394 -1.08300  2.25672 -0.84742 -0.07336
    ##  [6,] -0.09482  0.01596 -0.08071  0.01634 -0.84742  1.96328 -0.84977
    ##  [7,] -0.23819  0.09861  0.16192 -0.16922 -0.07336 -0.84977  2.08101
    ##  [8,]  0.18567  0.01051  0.03241  0.00314  0.03886 -0.12750 -0.83049
    ##  [9,] -0.00668 -0.28156  0.19288  0.09171  0.02559  0.20223 -0.34523
    ## [10,]  0.20875 -0.01171  0.03242 -0.17581  0.00089 -0.07387  0.17100
    ##           [,8]     [,9]    [,10]
    ##  [1,]  0.18567 -0.00668  0.20875
    ##  [2,]  0.01051 -0.28156 -0.01171
    ##  [3,]  0.03241  0.19288  0.03242
    ##  [4,]  0.00314  0.09171 -0.17581
    ##  [5,]  0.03886  0.02559  0.00089
    ##  [6,] -0.12750  0.20223 -0.07387
    ##  [7,] -0.83049 -0.34523  0.17100
    ##  [8,]  2.26882 -0.72086 -0.22616
    ##  [9,] -0.72086  1.89382 -0.80632
    ## [10,] -0.22616 -0.80632  1.47991

``` r
# lasso penalty (use CV for optimal lambda)
ADMMsigma(X)
```

    ## 
    ## Iterations:
    ## [1] 28
    ## 
    ## Tuning parameters:
    ##        lam  alpha
    ## [1,]  -1.5      1
    ## 
    ## Omega:
    ##           [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]
    ##  [1,]  2.28994 -1.33415 -0.35672 -0.00003  0.15211 -0.04247 -0.10777
    ##  [2,] -1.33415  2.44597 -0.91318 -0.04154  0.18517  0.00004  0.00002
    ##  [3,] -0.35672 -0.91318  2.48061 -1.02632 -0.16230  0.00005  0.02371
    ##  [4,] -0.00003 -0.04154 -1.02632  2.55481 -1.31350  0.00029 -0.05060
    ##  [5,]  0.15211  0.18517 -0.16230 -1.31350  2.49587 -0.98136  0.00007
    ##  [6,] -0.04247  0.00004  0.00005  0.00029 -0.98136  2.10982 -0.97205
    ##  [7,] -0.10777  0.00002  0.02371 -0.05060  0.00007 -0.97205  2.20031
    ##  [8,]  0.12504 -0.00006  0.04962 -0.00005  0.00022  0.00019 -0.98686
    ##  [9,]  0.00011 -0.22207  0.22169 -0.00032  0.02347  0.09974 -0.15748
    ## [10,]  0.17505 -0.00004  0.00012 -0.10194  0.00032  0.00023  0.01785
    ##           [,8]     [,9]    [,10]
    ##  [1,]  0.12504  0.00011  0.17505
    ##  [2,] -0.00006 -0.22207 -0.00004
    ##  [3,]  0.04962  0.22169  0.00012
    ##  [4,] -0.00005 -0.00032 -0.10194
    ##  [5,]  0.00022  0.02347  0.00032
    ##  [6,]  0.00019  0.09974  0.00023
    ##  [7,] -0.98686 -0.15748  0.01785
    ##  [8,]  2.44898 -0.84631 -0.13996
    ##  [9,] -0.84631  1.93152 -0.81514
    ## [10,] -0.13996 -0.81514  1.46955

``` r
# lasso penalty (lam = 0.1)
ADMMsigma(X, lam = 0.1)
```

    ## 
    ## Iterations:
    ## [1] 24
    ## 
    ## Tuning parameters:
    ##       lam  alpha
    ## [1,]   -1      1
    ## 
    ## Omega:
    ##           [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]
    ##  [1,]  1.60985 -0.79041 -0.25172  0.00024  0.00020  0.00025  0.00024
    ##  [2,] -0.79041  1.64849 -0.52626  0.00031  0.00024  0.00028  0.00026
    ##  [3,] -0.25172 -0.52626  1.65827 -0.63352 -0.04314 -0.00179  0.00014
    ##  [4,]  0.00024  0.00031 -0.63352  1.71555 -0.77371 -0.03489 -0.04512
    ##  [5,]  0.00020  0.00024 -0.04314 -0.77371  1.68970 -0.62681  0.00028
    ##  [6,]  0.00025  0.00028 -0.00179 -0.03489 -0.62681  1.51931 -0.60542
    ##  [7,]  0.00024  0.00026  0.00014 -0.04512  0.00028 -0.60542  1.53940
    ##  [8,]  0.00017  0.00017  0.00015  0.00020  0.00034  0.00024 -0.59452
    ##  [9,]  0.00005  0.00002  0.04437  0.00013  0.00028  0.00024 -0.09520
    ## [10,]  0.05796 -0.00002  0.00002  0.00012  0.00024  0.00024  0.00001
    ##           [,8]     [,9]    [,10]
    ##  [1,]  0.00017  0.00005  0.05796
    ##  [2,]  0.00017  0.00002 -0.00002
    ##  [3,]  0.00015  0.04437  0.00002
    ##  [4,]  0.00020  0.00013  0.00012
    ##  [5,]  0.00034  0.00028  0.00024
    ##  [6,]  0.00024  0.00024  0.00024
    ##  [7,] -0.59452 -0.09520  0.00001
    ##  [8,]  1.72699 -0.52601 -0.13471
    ##  [9,] -0.52601  1.40261 -0.54103
    ## [10,] -0.13471 -0.54103  1.16912

``` r
# elastic-net type penalty (use CV for optimal lambda)
ADMMsigma(X, alpha = 0.5)
```

    ## 
    ## Iterations:
    ## [1] 22
    ## 
    ## Tuning parameters:
    ##        lam  alpha
    ## [1,]  -1.5    0.5
    ## 
    ## Omega:
    ##           [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]
    ##  [1,]  2.18967 -1.20234 -0.40334 -0.00003  0.20655 -0.06088 -0.18379
    ##  [2,] -1.20234  2.28776 -0.83229 -0.12872  0.21535 -0.00008  0.06117
    ##  [3,] -0.40334 -0.83229  2.36916 -0.87895 -0.26219 -0.03494  0.09069
    ##  [4,] -0.00003 -0.12872 -0.87895  2.36333 -1.16545  0.00035 -0.11722
    ##  [5,]  0.20655  0.21535 -0.26219 -1.16545  2.34129 -0.90845 -0.00944
    ##  [6,] -0.06088 -0.00008 -0.03494  0.00035 -0.90845  2.02500 -0.91231
    ##  [7,] -0.18379  0.06117  0.09069 -0.11722 -0.00944 -0.91231  2.11922
    ##  [8,]  0.15641 -0.00007  0.04665  0.00002 -0.00003 -0.05239 -0.89259
    ##  [9,]  0.00013 -0.25470  0.21676  0.03541  0.02898  0.14145 -0.25626
    ## [10,]  0.19180 -0.00012 -0.00008 -0.13184  0.00011 -0.01866  0.08961
    ##           [,8]     [,9]    [,10]
    ##  [1,]  0.15641  0.00013  0.19180
    ##  [2,] -0.00007 -0.25470 -0.00012
    ##  [3,]  0.04665  0.21676 -0.00008
    ##  [4,]  0.00002  0.03541 -0.13184
    ##  [5,] -0.00003  0.02898  0.00011
    ##  [6,] -0.05239  0.14145 -0.01866
    ##  [7,] -0.89259 -0.25626  0.08961
    ##  [8,]  2.33390 -0.76593 -0.19236
    ##  [9,] -0.76593  1.90107 -0.80365
    ## [10,] -0.19236 -0.80365  1.46971

``` r
# elastic-net type penalty (use CV for optimal lambda and alpha)
ADMMsigma(X, lam = 10^seq(-8, 8, 0.1), alpha = seq(0, 1, 0.1))
```

    ## 
    ## Iterations:
    ## [1] 28
    ## 
    ## Tuning parameters:
    ##        lam  alpha
    ## [1,]  -1.6    0.9
    ## 
    ## Omega:
    ##           [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]
    ##  [1,]  2.37841 -1.38815 -0.38452 -0.00004  0.20384 -0.06018 -0.17761
    ##  [2,] -1.38815  2.54098 -0.95916 -0.07947  0.22402 -0.00001  0.04206
    ##  [3,] -0.38452 -0.95916  2.58683 -1.04716 -0.21999 -0.00271  0.06587
    ##  [4,] -0.00004 -0.07947 -1.04716  2.64274 -1.35948  0.00019 -0.07145
    ##  [5,]  0.20384  0.22402 -0.21999 -1.35948  2.58739 -1.01704  0.00012
    ##  [6,] -0.06018 -0.00001 -0.00271  0.00019 -1.01704  2.18345 -1.02640
    ##  [7,] -0.17761  0.04206  0.06587 -0.07145  0.00012 -1.02640  2.29349
    ##  [8,]  0.16840 -0.00008  0.03641  0.00002  0.00026  0.00020 -1.03388
    ##  [9,]  0.00011 -0.27336  0.25470 -0.00021  0.03497  0.12719 -0.20744
    ## [10,]  0.19575 -0.00004  0.00006 -0.12982  0.00024  0.00013  0.06322
    ##           [,8]     [,9]    [,10]
    ##  [1,]  0.16840  0.00011  0.19575
    ##  [2,] -0.00008 -0.27336 -0.00004
    ##  [3,]  0.03641  0.25470  0.00006
    ##  [4,]  0.00002 -0.00021 -0.12982
    ##  [5,]  0.00026  0.03497  0.00024
    ##  [6,]  0.00020  0.12719  0.00013
    ##  [7,] -1.03388 -0.20744  0.06322
    ##  [8,]  2.53490 -0.86801 -0.16460
    ##  [9,] -0.86801  2.00990 -0.85452
    ## [10,] -0.16460 -0.85452  1.51195

---
title: "ADMMsigma"
output: github_document
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

[![Build Status](https://travis-ci.org/MGallow/ADMMsigma.svg?branch=master)](https://travis-ci.org/MGallow/ADMMsigma)
[![CRAN_Status_Badge](http://www.r-pkg.org/badges/version/ADMMsigma)](https://cran.r-project.org/package=ADMMsigma)

## Overview

`ADMMsigma` is an R package that estimates a penalized precision matrix via the alternating direction method of multipliers (ADMM) algorithm. It currently supports a general elastic-net penalty that allows for both ridge and lasso-type penalties as special cases.

<p align="center">
  <img src = "https://github.com/MGallow/ADMMsigma/raw/master/vignettes/images/gif.gif"/>
</p>

A (possibly incomplete) list of functions contained in the package can be found below:

* `ADMMsigma()` computes the estimated precision matrix (ridge, lasso, and elastic-net type regularization optional)

* `RIDGEsigma()` computes the estimated ridge penalized precision matrix via closed-form solution

* `plot.ADMMsigma()` produces a heat map or line graph for cross validation errors

* `plot.RIDGEsigma()` produces a heat map or line graph for cross validation errors

See [vignette](https://mgallow.github.io/ADMMsigma/) or [manual](https://github.com/MGallow/ADMMsigma/blob/master/ADMMsigma.pdf).

## Installation

```{r, eval = FALSE}
# The easiest way to install is from CRAN
install.packages("ADMMsigma")

# You can also install the development version from GitHub:
# install.packages("devtools")
devtools::install_github("MGallow/ADMMsigma")
```

If there are any issues/bugs, please let me know: [github](https://github.com/MGallow/ADMMsigma/issues). You can also contact me via my [website](https://mgallow.github.io/). Pull requests are welcome!

## Usage

```{r, message = FALSE}
library(ADMMsigma)

# generate data from a sparse matrix
# first compute covariance matrix
S = matrix(0.7, nrow = 5, ncol = 5)
for (i in 1:5){
  for (j in 1:5){
    S[i, j] = S[i, j]^abs(i - j)
  }
}

# print oracle precision matrix (shrinkage might be useful)
(Omega = round(qr.solve(S), 3))

# generate 100 x 5 data matrix with rows drawn from iid N_p(0, S)
set.seed(123)
Z = matrix(rnorm(100*5), nrow = 100, ncol = 5)
out = eigen(S, symmetric = TRUE)
S.sqrt = out$vectors %*% diag(out$values^0.5) %*% t(out$vectors)
X = Z %*% S.sqrt


# print sample precision matrix (perhaps a bad estimate)
Sample = (nrow(X) - 1)/nrow(X)*cov(X)
round(qr.solve(Sample), 5)

# elastic-net type penalty (set tolerance to 1e-8)
ADMMsigma(X, tol.abs = 1e-8, tol.rel = 1e-8)

# lasso penalty (default tolerance)
ADMMsigma(X, alpha = 1)

# elastic-net penalty (alpha = 0.5)
ADMMsigma(X, alpha = 0.5)

# ridge penalty
ADMMsigma(X, alpha = 0)

# ridge penalty no ADMM
RIDGEsigma(X, lam = 10^seq(-8, 8, 0.01))

# produce CV heat map for ADMMsigma
ADMM = ADMMsigma(X, lam = 10^seq(-5, 5, 0.1), alpha = seq(0, 1, 0.1))
plot(ADMM, type = "heatmap")

# produce line graph for CV errors for ADMMsigma
plot(ADMM, type = "line")

# produce CV heat map for RIDGEsigma
RIDGE = RIDGEsigma(X, lam = 10^seq(-8, 8, 0.01))
plot(RIDGE, type = "heatmap")

# produce line graph for CV errors for RIDGEsigma
plot(RIDGE, type = "line")

```
